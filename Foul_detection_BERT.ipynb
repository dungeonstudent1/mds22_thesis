{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Foul_detection_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installing all packages\n",
        "\n"
      ],
      "metadata": {
        "id": "Um499UZKFoc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Important to run the cell twice, then click on \"Restart runtime\" button in output and run once again.\n"
      ],
      "metadata": {
        "id": "uAoDVH3sXVi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install squad_bert\n",
        "!pip uninstall tensorflow\n",
        "!pip uninstall tensorflow-gpu\n",
        "!pip install tensorflow-gpu==1.15.2 \n",
        "!pip install transformers==2.8.0\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d_MAEt0NEvv",
        "outputId": "bb220527-90b6-4dcf-9388-4e107f9cdde9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.7/dist-packages (0.17.4)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.22.0)\n",
            "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.5)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.4.417127.4579844)\n",
            "Requirement already satisfied: overrides==2.7.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.7.0)\n",
            "Requirement already satisfied: uvicorn==0.11.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.11.7)\n",
            "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.8)\n",
            "Requirement already satisfied: uvloop==0.14.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.14.0)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.17.3)\n",
            "Requirement already satisfied: tqdm==4.62.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.62.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.10.0)\n",
            "Requirement already satisfied: numpy==1.18.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.18.0)\n",
            "Requirement already satisfied: fastapi==0.47.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.47.1)\n",
            "Requirement already satisfied: pydantic==1.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.3)\n",
            "Requirement already satisfied: aio-pika==6.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (6.4.1)\n",
            "Requirement already satisfied: sacremoses==0.0.35 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.35)\n",
            "Requirement already satisfied: Cython==0.29.14 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.29.14)\n",
            "Requirement already satisfied: pytz==2019.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2019.1)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.21.2)\n",
            "Requirement already satisfied: ruamel.yaml==0.15.100 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.15.100)\n",
            "Requirement already satisfied: prometheus-client==0.7.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.7.1)\n",
            "Requirement already satisfied: pyopenssl==22.0.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (22.0.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Requirement already satisfied: pytelegrambotapi==3.6.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.6.7)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.4.5)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.25.3)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (1.7.2)\n",
            "Requirement already satisfied: aiormq<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (3.3.1)\n",
            "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Requirement already satisfied: cryptography>=35.0 in /usr/local/lib/python3.7/dist-packages (from pyopenssl==22.0.0->deeppavlov) (37.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.25.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2022.5.18.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
            "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (8.1)\n",
            "Requirement already satisfied: httptools==0.1.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.1.2)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.9.0)\n",
            "Requirement already satisfied: pamqp==2.3.0 in /usr/local/lib/python3.7/dist-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m2022-06-15 19:00:24.666 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-d_m2118j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmipt/bert.git /tmp/pip-req-build-d_m2118j\n",
            "  Resolved https://github.com/deepmipt/bert.git to commit 741d9bed9d52c6a9409ca27d8bf284615645618b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m2022-06-15 19:00:31.713 WARNING in 'deeppavlov.utils.pip_wrapper.pip_wrapper'['pip_wrapper'] at line 34: found tensorflow-gpu installed, so upgrading it instead of tensorflow\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15.5\n",
            "  Using cached tensorflow_gpu-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.18.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.46.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (4.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-gpu\n",
            "    Found existing installation: tensorflow-gpu 1.15.2\n",
            "    Uninstalling tensorflow-gpu-1.15.2:\n",
            "      Successfully uninstalled tensorflow-gpu-1.15.2\n",
            "Successfully installed tensorflow-gpu-1.15.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: tensorflow-gpu 1.15.5\n",
            "Uninstalling tensorflow-gpu-1.15.5:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_gpu-1.15.5.dist-info/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-gpu-1.15.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15.2\n",
            "  Using cached tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.46.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.62.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.24.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.35)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2022.6.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.96)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.22.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.9 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.27.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.25.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.9->boto3->transformers==2.8.0) (2.8.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "from deeppavlov.core.data.utils import download\n",
        "from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader\n",
        "from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator\n",
        "from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor\n",
        "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersPreprocessor\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.models.preprocessors.one_hotter import OneHotter\n",
        "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
        "from deeppavlov.models.bert.bert_classifier import BertClassifierModel\n",
        "from deeppavlov.metrics.accuracy import sets_accuracy\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "qm-gLdnZFsMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94dd2ff2-28db-4b20-d5d7-79b95cfcc148"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset preparation\n"
      ],
      "metadata": {
        "id": "jKflmC4t7Mys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 getting a dataset together; .csvs are uploaded manually\n",
        "foul = pd.read_csv(\"foul.csv\")\n",
        "nd = pd.read_csv(\"neutral_desc.csv\")\n",
        "neutral = nd[nd[\"toxic\"]==0]\n",
        "dataset = pd.concat([foul, neutral], ignore_index=True)"
      ],
      "metadata": {
        "id": "h7OpYb6KOF9Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 cleaning text part of the dataset\n",
        "def cleanup(text):\n",
        "    text = text.lower()\n",
        "    regular = r'[\\*+\\#+\\№\\\"\\-+\\+\\=+\\?+\\&\\^\\.+\\;\\,+\\>+\\(\\)\\/+\\:\\\\+]'\n",
        "    text = re.sub(regular, '', text)\n",
        "    return text\n",
        "\n",
        "text2 = []\n",
        "for text in dataset['comment']: \n",
        "    text = cleanup(text)\n",
        "    text2.append(text)\n",
        "dataset['descr'] = text2"
      ],
      "metadata": {
        "id": "9QIYb_DuPuoG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 splitting data into train-val-test\n",
        "xx = dataset.descr.values\n",
        "yy = dataset.toxic.values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(xx, yy, test_size=0.15, shuffle = True)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle = True)\n",
        "\n",
        "x_train = pd.DataFrame(data = x_train, columns=['text'])\n",
        "y_train = pd.DataFrame(data = y_train, columns=['tag'])\n",
        "train = pd.concat([x_train, y_train], axis=1)\n",
        "\n",
        "train.to_csv(\"train.csv\")\n",
        "train_path = \"./train.csv\"\n",
        "\n",
        "x_val = pd.DataFrame(data = x_val, columns=['text'])\n",
        "y_val = pd.DataFrame(data = y_val, columns=['tag'])\n",
        "val = pd.concat([x_val, y_val], axis=1)\n",
        "\n",
        "val.to_csv(\"val.csv\")\n",
        "val_path = \"./val.csv\"\n",
        "\n",
        "x_test = pd.DataFrame(data = x_test, columns=['text'])\n",
        "y_test = pd.DataFrame(data = y_test, columns=['tag'])\n",
        "test = pd.concat([x_test, y_test], axis=1)\n",
        "\n",
        "test.to_csv(\"test.csv\")\n",
        "test_path = \"./test.csv\"\n",
        "\n",
        "print(len(train), len(val), len(test))\n",
        "print(len(train) + len(val) + len(test))"
      ],
      "metadata": {
        "id": "wi9Sm9g77Pz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4975b818-af84-4ef1-8897-a9bfc569ef11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14652 3663 3233\n",
            "21548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhGENahOSASg",
        "outputId": "cbefee9a-96d6-4150-a247-a892114a9eb7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#things done manually now:\n",
        "# - \"data\" folder is created\n",
        "# - train-val-test .csv files are put there \n",
        "# - three BERT tar.gz files are uploaded\n",
        "\n",
        "reader = BasicClassificationDatasetReader()\n",
        "data = reader.read(data_path=\"./data\", \n",
        "                   train=\"train.csv\", valid=\"val.csv\",test = 'test.csv' ,\n",
        "                   x=\"text\", y=\"tag\")\n",
        "\n",
        "!tar -xf '/content/drive/MyDrive/mds22/ru_conversational_cased_L-12_H-768_A-12.tar.gz'\n",
        "#!tar -xf '/content/drive/MyDrive/MDS 2022/rubert_cased_L-12_H-768_A-12_v2.tar.gz'\n",
        "#!tar -xf '/content/drive/MyDrive/MDS 2022/sentence_ru_cased_L-12_H-768_A-12.tar.gz'\n"
      ],
      "metadata": {
        "id": "Lw9NFH4KGye8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "##Training phase: ruConvBERT\n",
        "\n"
      ],
      "metadata": {
        "id": "EfCimAogIpPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining helpful blocks\n",
        "\n",
        "def roc_auc(y_test,y_pred_tag):\n",
        "    y_pred_tag = [ y_p[1] for y_p in y_pred_tag ]\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_tag)\n",
        "    return roc_auc"
      ],
      "metadata": {
        "id": "876bTPHhuY-w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model elements\n",
        "\n",
        "iterator = BasicClassificationDatasetIterator(data, shuffle=True)\n",
        "\n",
        "PRETR_BERT_PATH = \"./ru_conversational_cased_L-12_H-768_A-12\"\n",
        "\n",
        "bert_preprocessor = BertPreprocessor(vocab_file=os.path.join(PRETR_BERT_PATH,\"vocab.txt\"),\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=256)\n",
        "\n",
        "input_features = bert_preprocessor([\"мама мыла раму\"])\n",
        "vocab = SimpleVocabulary(save_path=\"./binary_classes.dict\")\n",
        "vocab.fit(xx)\n",
        "\n",
        "#defining model\n",
        "bert_classifier = BertClassifierModel(\n",
        "    n_classes=2,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=False,\n",
        "    bert_config_file=os.path.join(PRETR_BERT_PATH,\"bert_config.json\"),\n",
        "    pretrained_bert=os.path.join(PRETR_BERT_PATH,\"bert_model.ckpt\"),\n",
        "    save_path=\"./model\",\n",
        "    load_path=\"./model\",\n",
        "    keep_prob=0.5,\n",
        "    learning_rate=1e-05,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgTZmb35IrDl",
        "outputId": "e12a58bb-c16f-4ecf-83a9-84012dede4dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-15 19:11:07.695 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for SimpleVocabulary in 'infer' mode. Using save path instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:161: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:97: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-15 19:11:26.720 INFO in 'deeppavlov.models.bert.bert_classifier'['bert_classifier'] at line 99: [initializing model with Bert from /content/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:103: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training phase\n",
        "\n",
        "best_score = 0\n",
        "patience = 3\n",
        "impatience = 0\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "DF_IN_USE = dataset\n",
        "plot_every = int(len(dataset)/BATCH_SIZE)\n",
        "\n",
        "\n",
        "for ep in range(30):\n",
        "    #train  \n",
        "    nbatches = 0\n",
        "    train_loss = []\n",
        "\n",
        "    for x, y in iterator.gen_batches(batch_size=BATCH_SIZE, \n",
        "                                     data_type=\"train\", shuffle=True):\n",
        "        x_feat = bert_preprocessor(x)\n",
        "        loss_dict = bert_classifier.train_on_batch(x_feat, y)\n",
        "        train_loss.append(loss_dict['loss'])\n",
        "        nbatches += 1\n",
        "        print('\\r' + str(nbatches*BATCH_SIZE/len(dataset)), end='' )\n",
        "    print('\\n')\n",
        "\n",
        "#val\n",
        "    y_valid_trues = []\n",
        "    y_valid_preds = []\n",
        "\n",
        "    for x, y in iterator.gen_batches(batch_size=BATCH_SIZE, \n",
        "                                        data_type=\"valid\", shuffle=True):\n",
        "            y_valid_pred = bert_classifier(bert_preprocessor(x))\n",
        "            y_valid_preds.extend(y_valid_pred)\n",
        "            y_valid_trues.extend(y)\n",
        "    \n",
        "    score = roc_auc(y_valid_trues, y_valid_preds)\n",
        "\n",
        "    y_valid_preds_class = np.argmax( np.array(y_valid_preds), axis=1 )\n",
        "    y_valid = np.array([int(i) for i in y_valid_trues])\n",
        "\n",
        "#score\n",
        "    pr, rec, f, _ = precision_recall_fscore_support(y_valid, y_valid_preds_class, average='weighted')\n",
        "    print(\"roc_auc\", score)\n",
        "    print(\"precision\", pr)\n",
        "    print(\"recall\", rec)\n",
        "    print(\"fscore_weighted\", f)\n",
        "    print(\"acc\", accuracy_score(y_valid, y_valid_preds_class))\n",
        "\n",
        "    print(\"Epochs done: {}. Valid roc_auc: {}\".format(ep + 1, score))\n",
        "    if score > best_score:\n",
        "        bert_classifier.save()\n",
        "        print(\"New best score. Saving model.\")\n",
        "        best_score = score    \n",
        "        impatience = 0\n",
        "    else:\n",
        "        impatience += 1\n",
        "        if impatience == patience:\n",
        "            print(\"Out of patience. Stop training.\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "fczvAo0rJsqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d06b31-2d87-4276-c88b-62accb970efd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6801559309448673\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 19:28:39.388 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc_auc 0.9988091219271066\n",
            "precision 0.990186478638567\n",
            "recall 0.9901719901719902\n",
            "fscore_weighted 0.9901684774010349\n",
            "acc 0.9901719901719902\n",
            "Epochs done: 1. Valid roc_auc: 0.9988091219271066\n",
            "New best score. Saving model.\n",
            "0.6801559309448673\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 19:43:50.908 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc_auc 0.9993661309574046\n",
            "precision 0.9872130616584823\n",
            "recall 0.9871689871689872\n",
            "fscore_weighted 0.9871743196804774\n",
            "acc 0.9871689871689872\n",
            "Epochs done: 2. Valid roc_auc: 0.9993661309574046\n",
            "New best score. Saving model.\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9987652665083251\n",
            "precision 0.9907665567642725\n",
            "recall 0.9907179907179907\n",
            "fscore_weighted 0.9907123466522223\n",
            "acc 0.9907179907179907\n",
            "Epochs done: 3. Valid roc_auc: 0.9987652665083251\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9981234100526868\n",
            "precision 0.9874718022616445\n",
            "recall 0.9874419874419874\n",
            "fscore_weighted 0.9874461974250468\n",
            "acc 0.9874419874419874\n",
            "Epochs done: 4. Valid roc_auc: 0.9981234100526868\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9988406194615579\n",
            "precision 0.9885421049164075\n",
            "recall 0.9885339885339886\n",
            "fscore_weighted 0.988530591035884\n",
            "acc 0.9885339885339886\n",
            "Epochs done: 5. Valid roc_auc: 0.9988406194615579\n",
            "Out of patience. Stop training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training phase: ruBERT\n"
      ],
      "metadata": {
        "id": "-Bu_pBv1E_cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model elements\n",
        "\n",
        "\n",
        "PRETR_BERT_PATH = \"./rubert_cased_L-12_H-768_A-12_v2\"\n",
        "\n",
        "bert_preprocessor = BertPreprocessor(vocab_file=os.path.join(PRETR_BERT_PATH,\"vocab.txt\"),\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=256)\n",
        "\n",
        "#defining model\n",
        "bert_classifier = BertClassifierModel(\n",
        "    n_classes=2,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=False,\n",
        "    bert_config_file=os.path.join(PRETR_BERT_PATH,\"bert_config.json\"),\n",
        "    pretrained_bert=os.path.join(PRETR_BERT_PATH,\"bert_model.ckpt\"),\n",
        "    save_path=\"./model\",\n",
        "    load_path=\"./model\",\n",
        "    keep_prob=0.5,\n",
        "    learning_rate=1e-05,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0)\n",
        "\n",
        "#Training phase\n",
        "\n",
        "best_score = 0\n",
        "patience = 3\n",
        "impatience = 0\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "DF_IN_USE = dataset\n",
        "plot_every = int(len(dataset)/BATCH_SIZE)\n",
        "\n",
        "\n",
        "for ep in range(30):\n",
        "    #train  \n",
        "    nbatches = 0\n",
        "    train_loss = []\n",
        "\n",
        "    for x, y in iterator.gen_batches(batch_size=BATCH_SIZE, \n",
        "                                     data_type=\"train\", shuffle=True):\n",
        "        x_feat = bert_preprocessor(x)\n",
        "        loss_dict = bert_classifier.train_on_batch(x_feat, y)\n",
        "        train_loss.append(loss_dict['loss'])\n",
        "        nbatches += 1\n",
        "        print('\\r' + str(nbatches*BATCH_SIZE/len(dataset)), end='' )\n",
        "    print('\\n')\n",
        "\n",
        "#val\n",
        "    y_valid_trues = []\n",
        "    y_valid_preds = []\n",
        "\n",
        "    for x, y in iterator.gen_batches(batch_size=BATCH_SIZE, \n",
        "                                        data_type=\"valid\", shuffle=True):\n",
        "            y_valid_pred = bert_classifier(bert_preprocessor(x))\n",
        "            y_valid_preds.extend(y_valid_pred)\n",
        "            y_valid_trues.extend(y)\n",
        "    \n",
        "    score = roc_auc(y_valid_trues, y_valid_preds)\n",
        "\n",
        "    y_valid_preds_class = np.argmax( np.array(y_valid_preds), axis=1 )\n",
        "    y_valid = np.array([int(i) for i in y_valid_trues])\n",
        "\n",
        "#score\n",
        "    pr, rec, f, _ = precision_recall_fscore_support(y_valid, y_valid_preds_class, average='weighted')\n",
        "    print(\"roc_auc\", score)\n",
        "    print(\"precision\", pr)\n",
        "    print(\"recall\", rec)\n",
        "    print(\"fscore_weighted\", f)\n",
        "    print(\"acc\", accuracy_score(y_valid, y_valid_preds_class))\n",
        "\n",
        "    print(\"Epochs done: {}. Valid roc_auc: {}\".format(ep + 1, score))\n",
        "    if score > best_score:\n",
        "        bert_classifier.save()\n",
        "        print(\"New best score. Saving model.\")\n",
        "        best_score = score    \n",
        "        impatience = 0\n",
        "    else:\n",
        "        impatience += 1\n",
        "        if impatience == patience:\n",
        "            print(\"Out of patience. Stop training.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RAFhvohYFMnu",
        "outputId": "7601a23f-fea5-4598-b2de-b736f2770cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 11:25:16.686 INFO in 'deeppavlov.models.bert.bert_classifier'['bert_classifier'] at line 99: [initializing model with Bert from /content/rubert_cased_L-12_H-768_A-12_v2/bert_model.ckpt]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/rubert_cased_L-12_H-768_A-12_v2/bert_model.ckpt\n",
            "0.6801559309448673\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 11:41:00.311 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc_auc 0.9989970718132941\n",
            "precision 0.9863517267665602\n",
            "recall 0.9863499863499864\n",
            "fscore_weighted 0.9863460715191523\n",
            "acc 0.9863499863499864\n",
            "Epochs done: 1. Valid roc_auc: 0.9989970718132941\n",
            "New best score. Saving model.\n",
            "0.6801559309448673\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 11:56:35.379 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc_auc 0.9991002431267604\n",
            "precision 0.9837176883038591\n",
            "recall 0.9836199836199836\n",
            "fscore_weighted 0.9836015176924269\n",
            "acc 0.9836199836199836\n",
            "Epochs done: 2. Valid roc_auc: 0.9991002431267604\n",
            "New best score. Saving model.\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9990653981897601\n",
            "precision 0.9874419874419874\n",
            "recall 0.9874419874419874\n",
            "fscore_weighted 0.9874419874419874\n",
            "acc 0.9874419874419874\n",
            "Epochs done: 3. Valid roc_auc: 0.9990653981897601\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9989646508719112\n",
            "precision 0.9863670915441017\n",
            "recall 0.9863499863499864\n",
            "fscore_weighted 0.9863537644942656\n",
            "acc 0.9863499863499864\n",
            "Epochs done: 4. Valid roc_auc: 0.9989646508719112\n",
            "0.3066641915723037"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-097f651be678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                                      data_type=\"train\", shuffle=True):\n\u001b[1;32m     42\u001b[0m         \u001b[0mx_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, features, y)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_ph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training phase: Sentence ruBERT"
      ],
      "metadata": {
        "id": "kDHljYhJMZKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model elements\n",
        "\n",
        "\n",
        "PRETR_BERT_PATH = \"./sentence_ru_cased_L-12_H-768_A-12\"\n",
        "\n",
        "bert_preprocessor = BertPreprocessor(vocab_file=os.path.join(PRETR_BERT_PATH,\"vocab.txt\"),\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=256)\n",
        "\n",
        "#defining model\n",
        "bert_classifier = BertClassifierModel(\n",
        "    n_classes=2,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=False,\n",
        "    bert_config_file=os.path.join(PRETR_BERT_PATH,\"bert_config.json\"),\n",
        "    pretrained_bert=os.path.join(PRETR_BERT_PATH,\"bert_model.ckpt\"),\n",
        "    save_path=\"./model\",\n",
        "    load_path=\"./model\",\n",
        "    keep_prob=0.5,\n",
        "    learning_rate=1e-05,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0)\n",
        "\n",
        "#Training phase\n",
        "\n",
        "best_score = 0\n",
        "patience = 3\n",
        "impatience = 0\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "DF_IN_USE = dataset\n",
        "plot_every = int(len(dataset)/BATCH_SIZE)\n",
        "\n",
        "\n",
        "for ep in range(30):\n",
        "    #train  \n",
        "    nbatches = 0\n",
        "    train_loss = []\n",
        "\n",
        "    for x, y in iterator.gen_batches(batch_size=BATCH_SIZE, \n",
        "                                     data_type=\"train\", shuffle=True):\n",
        "        x_feat = bert_preprocessor(x)\n",
        "        loss_dict = bert_classifier.train_on_batch(x_feat, y)\n",
        "        train_loss.append(loss_dict['loss'])\n",
        "        nbatches += 1\n",
        "        print('\\r' + str(nbatches*BATCH_SIZE/len(dataset)), end='' )\n",
        "    print('\\n')\n",
        "\n",
        "#val\n",
        "    y_valid_trues = []\n",
        "    y_valid_preds = []\n",
        "\n",
        "    for x, y in iterator.gen_batches(batch_size=BATCH_SIZE, \n",
        "                                        data_type=\"valid\", shuffle=True):\n",
        "            y_valid_pred = bert_classifier(bert_preprocessor(x))\n",
        "            y_valid_preds.extend(y_valid_pred)\n",
        "            y_valid_trues.extend(y)\n",
        "    \n",
        "    score = roc_auc(y_valid_trues, y_valid_preds)\n",
        "\n",
        "    y_valid_preds_class = np.argmax( np.array(y_valid_preds), axis=1 )\n",
        "    y_valid = np.array([int(i) for i in y_valid_trues])\n",
        "\n",
        "#score\n",
        "    pr, rec, f, _ = precision_recall_fscore_support(y_valid, y_valid_preds_class, average='weighted')\n",
        "    print(\"roc_auc\", score)\n",
        "    print(\"precision\", pr)\n",
        "    print(\"recall\", rec)\n",
        "    print(\"fscore_weighted\", f)\n",
        "    print(\"acc\", accuracy_score(y_valid, y_valid_preds_class))\n",
        "\n",
        "    print(\"Epochs done: {}. Valid roc_auc: {}\".format(ep + 1, score))\n",
        "    if score > best_score:\n",
        "        bert_classifier.save()\n",
        "        print(\"New best score. Saving model.\")\n",
        "        best_score = score    \n",
        "        impatience = 0\n",
        "    else:\n",
        "        impatience += 1\n",
        "        if impatience == patience:\n",
        "            print(\"Out of patience. Stop training.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRUitHNXF97e",
        "outputId": "dc425c16-eb79-4eb2-ce55-bdb6da68add7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 12:36:18.542 INFO in 'deeppavlov.models.bert.bert_classifier'['bert_classifier'] at line 99: [initializing model with Bert from /content/sentence_ru_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/sentence_ru_cased_L-12_H-768_A-12/bert_model.ckpt\n",
            "0.6801559309448673\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 12:52:01.858 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc_auc 0.9992734073136796\n",
            "precision 0.9872389063727125\n",
            "recall 0.9871689871689872\n",
            "fscore_weighted 0.9871570592405526\n",
            "acc 0.9871689871689872\n",
            "Epochs done: 1. Valid roc_auc: 0.9992734073136796\n",
            "New best score. Saving model.\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9991938699574832\n",
            "precision 0.9885407232762149\n",
            "recall 0.9885339885339886\n",
            "fscore_weighted 0.9885298599874709\n",
            "acc 0.9885339885339886\n",
            "Epochs done: 2. Valid roc_auc: 0.9991938699574832\n",
            "0.6801559309448673\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-15 13:23:08.342 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc_auc 0.9992749223109404\n",
            "precision 0.9869120111764246\n",
            "recall 0.9868959868959869\n",
            "fscore_weighted 0.9868893236673711\n",
            "acc 0.9868959868959869\n",
            "Epochs done: 3. Valid roc_auc: 0.9992749223109404\n",
            "New best score. Saving model.\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9992075049328312\n",
            "precision 0.9871771913056512\n",
            "recall 0.9871689871689872\n",
            "fscore_weighted 0.9871712218652453\n",
            "acc 0.9871689871689872\n",
            "Epochs done: 4. Valid roc_auc: 0.9992075049328312\n",
            "0.6801559309448673\n",
            "\n",
            "roc_auc 0.9989879818297288\n",
            "precision 0.9882624500444407\n",
            "recall 0.9882609882609883\n",
            "fscore_weighted 0.9882580487894633\n",
            "acc 0.9882609882609883\n",
            "Epochs done: 5. Valid roc_auc: 0.9989879818297288\n",
            "0.24874698347874513"
          ]
        }
      ]
    }
  ]
}